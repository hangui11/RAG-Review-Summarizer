{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d9bfb72",
   "metadata": {},
   "source": [
    "# Review Summarizer using RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c761638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "c:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\n",
      "Running on: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pytextrank\n",
    "import evaluate\n",
    "\n",
    "\n",
    "# Setup Device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Running on: {DEVICE}\")\n",
    "\n",
    "# Model Config\n",
    "RETRIEVER_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "GENERATOR_MODEL_ID = \"Qwen/Qwen3-4B-Instruct-2507\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f14cb2",
   "metadata": {},
   "source": [
    "Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e43af459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LOADING DATASETS ---\n",
      "Beauty Dataset Loaded: 701528 rows\n",
      "Music Dataset Loaded: 130434 rows\n",
      "SAMSum Dataset Loaded: 819 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"--- LOADING DATASETS ---\")\n",
    "\n",
    "# 1. Define Direct URLs to the raw data files\n",
    "url_beauty = \"https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/resolve/main/raw/review_categories/All_Beauty.jsonl\"\n",
    "url_music = \"https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/resolve/main/raw/review_categories/Digital_Music.jsonl\"\n",
    "\n",
    "ds_beauty = load_dataset(\"json\", data_files={\"train\": url_beauty}, split=\"train\")\n",
    "ds_music = load_dataset(\"json\", data_files={\"train\": url_music}, split=\"train\")\n",
    "\n",
    "# 2. Load SAMSum (Benchmark Data)\n",
    "# Only loading 'test' split to keep it lightweight\n",
    "ds_samsum = load_dataset(\"knkarthick/samsum\", split=\"test\")\n",
    "\n",
    "print(f\"Beauty Dataset Loaded: {len(ds_beauty)} rows\")\n",
    "print(f\"Music Dataset Loaded: {len(ds_music)} rows\")\n",
    "print(f\"SAMSum Dataset Loaded: {len(ds_samsum)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489f3a9",
   "metadata": {},
   "source": [
    "Prepare the full external knowledge corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6dbfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus prepared within beauty and music\n"
     ]
    }
   ],
   "source": [
    "def prepare_full_corpus(dataset, limit=100000):\n",
    "    \"\"\"\n",
    "    Converts dataset rows to a list of strings.\n",
    "    Limits to 100k rows to keep RAM usage safe during prototyping.\n",
    "    Set limit=None to use everything.\n",
    "    \"\"\"\n",
    "    corpus = []\n",
    "    for i, row in enumerate(dataset):\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "        text = f\"Rating: {row['rating']}\\nTitle: {row['title']}\\nReview: {row['text']}\"\n",
    "        corpus.append(text)\n",
    "    return corpus\n",
    "\n",
    "corpus_beauty = prepare_full_corpus(ds_beauty)\n",
    "corpus_music = prepare_full_corpus(ds_music)\n",
    "\n",
    "corpus = corpus_beauty+corpus_music\n",
    "print('Corpus prepared within beauty and music')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d4ab54",
   "metadata": {},
   "source": [
    "Employ pre-trained embedding model and utilize a dense vector indexing to store the embeddings of the entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c926ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embedder sentence-transformers/all-MiniLM-L6-v2 on GPU...\n",
      "Encoding 200000 documents...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd597dc2007443a955771fc11b9e907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding complete. Cleaning up VRAM...\n",
      "SUCCESS: Indices built and GPU memory cleared.\n"
     ]
    }
   ],
   "source": [
    "def build_faiss_index_and_clean(corpus, model_name):\n",
    "    print(f\"Loading Embedder {model_name} on GPU...\")\n",
    "    embed_model = SentenceTransformer(model_name, device=DEVICE)\n",
    "    \n",
    "    print(f\"Encoding {len(corpus)} documents...\")\n",
    "    embeddings = embed_model.encode(corpus, batch_size=32, show_progress_bar=True, convert_to_numpy=True)\n",
    "    \n",
    "    # Build FAISS Index\n",
    "    vector_dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(vector_dim)\n",
    "    index.add(embeddings)\n",
    "    \n",
    "    print(\"Encoding complete. Cleaning up VRAM...\")\n",
    "    \n",
    "    del embed_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return index\n",
    "\n",
    "# Build Indices sequentially\n",
    "index = build_faiss_index_and_clean(corpus, RETRIEVER_MODEL)\n",
    "\n",
    "print(\"SUCCESS: Indices built and GPU memory cleared.\")\n",
    "\n",
    "embed_model_cpu = SentenceTransformer(RETRIEVER_MODEL, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b5f845",
   "metadata": {},
   "source": [
    "Pre-trained LLM model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ffa25b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen/Qwen3-4B-Instruct-2507...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ecd5c48dc0499d9fc65d880a77c52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Qwen/Qwen3-4B-Instruct-2507 loaded.\n"
     ]
    }
   ],
   "source": [
    "# 4-bit Quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(f\"Loading {GENERATOR_MODEL_ID}...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(GENERATOR_MODEL_ID, trust_remote_code=True)\n",
    "    \n",
    "    model_qwen3 = AutoModelForCausalLM.from_pretrained(\n",
    "        GENERATOR_MODEL_ID, \n",
    "        quantization_config=bnb_config, \n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # Safety check for pad token\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "    print(f\"Success! {GENERATOR_MODEL_ID} loaded.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Qwen3: {e}\")\n",
    "\n",
    "def generate_with_qwen3(prompt, content, temperature=0.7):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        generated_ids = model_qwen3.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=512,\n",
    "            temperature=temperature,\n",
    "            top_p=0.8,         \n",
    "            top_k=20,          \n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f5bd49",
   "metadata": {},
   "source": [
    "Construct the query rag with a specific prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d7bb436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag(query, index, corpus, k=5):\n",
    "    # Encode query\n",
    "    q_emb = embed_model_cpu.encode([query])\n",
    "    \n",
    "    # Retrieve (FAISS)\n",
    "    D, I = index.search(np.array(q_emb), k)\n",
    "    retrieved_docs = [corpus[i] for i in I[0]]\n",
    "    \n",
    "    # Format Context\n",
    "    context_str = \"\\n\\n\".join([f\"Review {i+1}: {doc}\" for i, doc in enumerate(retrieved_docs)])\n",
    "    \n",
    "    # Construct Prompt\n",
    "    prompt = f\"\"\"Summarize the user's question based ONLY on the provided reviews below. \n",
    "If the reviews discuss different products, specify which product has which pros/cons.\n",
    "\n",
    "Reviews:\n",
    "{context_str}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\"\"\"\n",
    "    return generate_with_qwen3(prompt, content=\"You are a helpful and professional assistant specialized in summarizing reviews.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578594f1",
   "metadata": {},
   "source": [
    "Build a LLM-as-a-Judge to evaluate with predefined criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ad03c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_judge_score(question, source_text, summary_to_evaluate):\n",
    "    prompt = f\"\"\"\n",
    "You are a very strict, professional evaluator.\n",
    "Act as an expert teacher grading a student answer.\n",
    "\n",
    "User Question:\n",
    "{question}\n",
    "\n",
    "Source Text:\n",
    "{source_text}\n",
    "\n",
    "Summary to Evaluate:\n",
    "{summary_to_evaluate}\n",
    "\n",
    "Evaluate the summary from 1 to 10. You must prioritize the following CRITICAL criteria above all else:\n",
    "\n",
    "1. ACCURACY (Critical): The summary must be factually correct and match the source text exactly.\n",
    "2. FAITHFULNESS (Critical): The summary must NOT add information that is not explicitly supported by the source. Hallucinations should result in a low score.\n",
    "3. RELEVANCE (Critical): The summary must directly answer the user's specific question.\n",
    "4. COVERAGE (Critical): The summary must include the most important points needed to answer the question.\n",
    "\n",
    "Secondary Criteria:\n",
    "5. CONCISENESS: The summary is clear, brief, and avoids unnecessary details.\n",
    "6. COHERENCE: The summary is logically structured.\n",
    "7. REDUNDANCY: The summary avoids repetition.\n",
    "\n",
    "Final instruction:\n",
    "- If the summary fails on Accuracy or Faithfulness, the score must be below 5.\n",
    "- Give a SINGLE score from 1 (very poor) to 10 (excellent).\n",
    "- Reply ONLY with the number (e.g., 7 or 10). Do not write sentences.\n",
    "\"\"\"\n",
    "    try:\n",
    "        score_text = generate_with_qwen3(\n",
    "            prompt, \n",
    "            content=\"You are an impartial judge. Reply ONLY with a digit.\"\n",
    "        )\n",
    "        \n",
    "        digits = ''.join(filter(str.isdigit, score_text))\n",
    "        \n",
    "        if not digits:\n",
    "            return 3\n",
    "            \n",
    "        score = int(digits)\n",
    "        \n",
    "        return min(score, 10)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Judge Error: {e}\")\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb86f01",
   "metadata": {},
   "source": [
    "Before vs. After Retriever Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f6574ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Domain: Beauty | Query: What do users with sensitive skin say about the texture and greasiness of the moisturizers?\n",
      "  > Running 'Before' (Naive) scenario...\n",
      "  > Judge is evaluating TextRank...\n",
      "  > Judge is evaluating BART...\n",
      "  > Judge is evaluating Qwen RAG...\n",
      "  > Running 'After' (Retriever) scenario...\n",
      "  > Judge is evaluating TextRank...\n",
      "  > Judge is evaluating BART...\n",
      "  > Judge is evaluating Qwen RAG...\n",
      "\n",
      "Processing Domain: Music | Query: Do customers think the sound quality justifies the price, and are there complaints about comfort?\n",
      "  > Running 'Before' (Naive) scenario...\n",
      "  > Judge is evaluating TextRank...\n",
      "  > Judge is evaluating BART...\n",
      "  > Judge is evaluating Qwen RAG...\n",
      "  > Running 'After' (Retriever) scenario...\n",
      "  > Judge is evaluating TextRank...\n",
      "  > Judge is evaluating BART...\n",
      "  > Judge is evaluating Qwen RAG...\n",
      "\n",
      "--- FINAL COMPARISON: BEFORE vs AFTER RETRIEVER ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Model</th>\n",
       "      <th>Output</th>\n",
       "      <th>Judge Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beauty</td>\n",
       "      <td>After (With Retriever)</td>\n",
       "      <td>BART</td>\n",
       "      <td>Review: Excellent for sensitive skin! Extremely moisturizing! Stock up because you're going to love how your skin feels and smells. Rating: 5.0 emphatically. Reviewer: \"I have pretty sensitive skin, and they feel great so far\"</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beauty</td>\n",
       "      <td>Before (Naive)</td>\n",
       "      <td>BART</td>\n",
       "      <td>Review: This spray is really nice. It smells really good, goes on really fine, and does the trick. I will say it feels like you need a lot of it though to get the texture I want.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Beauty</td>\n",
       "      <td>After (RAG)</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>Users with sensitive skin praise the moisturizer for its smooth texture, quick absorption, and non-greasy feel. They highlight that it is extremely moisturizing, gentle, and does not cause breakouts or irritation. There is no mention of greasiness, as all reviews emphasize that the product is pleasant, non-irritating, and well-tolerated on sensitive skin. \\n\\nProduct: All reviews refer to the same moisturizer, with no distinction between different products.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beauty</td>\n",
       "      <td>Before (Naive)</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>The provided reviews do not contain information about users with sensitive skin or their experiences with texture and greasiness of moisturizers. Therefore, based solely on the reviews, the question cannot be accurately summarized or answered.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beauty</td>\n",
       "      <td>After (With Retriever)</td>\n",
       "      <td>TextRank</td>\n",
       "      <td>Rating: 5.0\\nTitle: Great for sensitive skin\\nReview: Excellent for sensitive skin! so if you have sensitive skin it's just wonderful it doesn't make me break out is just so good\\n\\nRating:</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beauty</td>\n",
       "      <td>Before (Naive)</td>\n",
       "      <td>TextRank</td>\n",
       "      <td>Rating: 1.0\\nTitle: Synthetic feeling\\nReview: Felt synthetic\\n\\nRating: 5.0\\nTitle: A+\\nReview: Love it I am comparing to other brands with yucky chemicals so I'm gonna stick with this.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Music</td>\n",
       "      <td>After (With Retriever)</td>\n",
       "      <td>BART</td>\n",
       "      <td>The Fit is snug, quality is silky and a good thickness. Very comfortable. Also recvd two. Great product at a good price.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Music</td>\n",
       "      <td>Before (Naive)</td>\n",
       "      <td>BART</td>\n",
       "      <td>Review: This spray is really nice. It smells really good, goes on really fine, and does the trick. I will say it feels like you need a lot of it though to get the texture I want.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Music</td>\n",
       "      <td>After (RAG)</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>The user is asking whether customers find the sound quality justifies the price and if there are complaints about comfort.\\n\\nBased on the reviews:\\n\\n- Sound quality is mentioned positively in Review 1 (\"Excellent sound\") and is implied in Review 5 (\"It's the quality and comfort as you see in picture\"), though no explicit comparison to price is made.\\n- Comfort is consistently praised: Reviews 3, 4, and 5 highlight comfort (\"Super comfortable\", \"comfortable enough to wear all day\", \"very comfortable\"), with no complaints.\\n- Price is discussed in Reviews 2 and 3, where users note it is \"a little bit pricey\" or \"tad pricey,\" but still consider it \"worth it\" or \"good value,\" indicating that despite the cost, customers feel it's justified.\\n\\nNo customer complaints about comfort are present. The sound quality is viewed positively, and while the price is acknowledged as higher, it is not seen as a dealbreaker.\\n\\nFinal Summary:  \\nCustomers do not have complaints about comfort. Sound quality is considered excellent. While the product is priced higher than some alternatives (e.g., \"not buying the ears in the park\"), customers believe the price is justified due to comfort, quality, and performance.  \\n\\nThus, the answer to the user's question is:  \\nYes, customers think the sound quality justifies the price, and there are no complaints about comfort.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Music</td>\n",
       "      <td>Before (Naive)</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>The user's question is based on a misunderstanding of the review content. The reviews discuss a product related to scent and texture (likely a hair spray or similar), not sound quality or price justification. There are no mentions of sound quality, price, or comfort in the context of auditory or physical comfort. Therefore, the question is irrelevant to the provided reviews. \\n\\nCorrect summary: The user is asking about sound quality and comfort, but the reviews pertain to scent, texture, and fragrance preference—there are no references to sound quality or comfort in the context provided.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Music</td>\n",
       "      <td>After (With Retriever)</td>\n",
       "      <td>TextRank</td>\n",
       "      <td>Rating: 5.0\\nTitle: Excellent sound, and only minor indications that it had ...\\n Review: Excellent sound, and only minor indications that it had ever been out of the package.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Music</td>\n",
       "      <td>Before (Naive)</td>\n",
       "      <td>TextRank</td>\n",
       "      <td>Rating: 1.0\\nTitle: Synthetic feeling\\nReview: Felt synthetic\\n\\nRating: 5.0\\nTitle: A+\\nReview: Love it I am comparing to other brands with yucky chemicals so I'm gonna stick with this.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Domain                    Mode     Model  \\\n",
       "4   Beauty  After (With Retriever)      BART   \n",
       "1   Beauty          Before (Naive)      BART   \n",
       "5   Beauty             After (RAG)     Qwen3   \n",
       "2   Beauty          Before (Naive)     Qwen3   \n",
       "3   Beauty  After (With Retriever)  TextRank   \n",
       "0   Beauty          Before (Naive)  TextRank   \n",
       "10   Music  After (With Retriever)      BART   \n",
       "7    Music          Before (Naive)      BART   \n",
       "11   Music             After (RAG)     Qwen3   \n",
       "8    Music          Before (Naive)     Qwen3   \n",
       "9    Music  After (With Retriever)  TextRank   \n",
       "6    Music          Before (Naive)  TextRank   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Output  \\\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Review: Excellent for sensitive skin! Extremely moisturizing! Stock up because you're going to love how your skin feels and smells. Rating: 5.0 emphatically. Reviewer: \"I have pretty sensitive skin, and they feel great so far\"   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Review: This spray is really nice. It smells really good, goes on really fine, and does the trick. I will say it feels like you need a lot of it though to get the texture I want.   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Users with sensitive skin praise the moisturizer for its smooth texture, quick absorption, and non-greasy feel. They highlight that it is extremely moisturizing, gentle, and does not cause breakouts or irritation. There is no mention of greasiness, as all reviews emphasize that the product is pleasant, non-irritating, and well-tolerated on sensitive skin. \\n\\nProduct: All reviews refer to the same moisturizer, with no distinction between different products.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The provided reviews do not contain information about users with sensitive skin or their experiences with texture and greasiness of moisturizers. Therefore, based solely on the reviews, the question cannot be accurately summarized or answered.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Rating: 5.0\\nTitle: Great for sensitive skin\\nReview: Excellent for sensitive skin! so if you have sensitive skin it's just wonderful it doesn't make me break out is just so good\\n\\nRating:   \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Rating: 1.0\\nTitle: Synthetic feeling\\nReview: Felt synthetic\\n\\nRating: 5.0\\nTitle: A+\\nReview: Love it I am comparing to other brands with yucky chemicals so I'm gonna stick with this.   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 The Fit is snug, quality is silky and a good thickness. Very comfortable. Also recvd two. Great product at a good price.   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Review: This spray is really nice. It smells really good, goes on really fine, and does the trick. I will say it feels like you need a lot of it though to get the texture I want.   \n",
       "11  The user is asking whether customers find the sound quality justifies the price and if there are complaints about comfort.\\n\\nBased on the reviews:\\n\\n- Sound quality is mentioned positively in Review 1 (\"Excellent sound\") and is implied in Review 5 (\"It's the quality and comfort as you see in picture\"), though no explicit comparison to price is made.\\n- Comfort is consistently praised: Reviews 3, 4, and 5 highlight comfort (\"Super comfortable\", \"comfortable enough to wear all day\", \"very comfortable\"), with no complaints.\\n- Price is discussed in Reviews 2 and 3, where users note it is \"a little bit pricey\" or \"tad pricey,\" but still consider it \"worth it\" or \"good value,\" indicating that despite the cost, customers feel it's justified.\\n\\nNo customer complaints about comfort are present. The sound quality is viewed positively, and while the price is acknowledged as higher, it is not seen as a dealbreaker.\\n\\nFinal Summary:  \\nCustomers do not have complaints about comfort. Sound quality is considered excellent. While the product is priced higher than some alternatives (e.g., \"not buying the ears in the park\"), customers believe the price is justified due to comfort, quality, and performance.  \\n\\nThus, the answer to the user's question is:  \\nYes, customers think the sound quality justifies the price, and there are no complaints about comfort.   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The user's question is based on a misunderstanding of the review content. The reviews discuss a product related to scent and texture (likely a hair spray or similar), not sound quality or price justification. There are no mentions of sound quality, price, or comfort in the context of auditory or physical comfort. Therefore, the question is irrelevant to the provided reviews. \\n\\nCorrect summary: The user is asking about sound quality and comfort, but the reviews pertain to scent, texture, and fragrance preference—there are no references to sound quality or comfort in the context provided.   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Rating: 5.0\\nTitle: Excellent sound, and only minor indications that it had ...\\n Review: Excellent sound, and only minor indications that it had ever been out of the package.     \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Rating: 1.0\\nTitle: Synthetic feeling\\nReview: Felt synthetic\\n\\nRating: 5.0\\nTitle: A+\\nReview: Love it I am comparing to other brands with yucky chemicals so I'm gonna stick with this.   \n",
       "\n",
       "    Judge Score  \n",
       "4             3  \n",
       "1             2  \n",
       "5            10  \n",
       "2             0  \n",
       "3             8  \n",
       "0             2  \n",
       "10            2  \n",
       "7             0  \n",
       "11           10  \n",
       "8             1  \n",
       "9             2  \n",
       "6             2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Spacy TextRank\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    nlp = spacy.blank(\"en\")\n",
    "\n",
    "if \"textrank\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"textrank\")\n",
    "\n",
    "# Setup BART (Abstractive Summarization)\n",
    "bart_pipeline = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0) # Change to -1 for CPU\n",
    "\n",
    "queries = {\n",
    "    \"Beauty\": \"What do users with sensitive skin say about the texture and greasiness of the moisturizers?\",\n",
    "    \"Music\": \"Do customers think the sound quality justifies the price, and are there complaints about comfort?\"\n",
    "}\n",
    "\n",
    "results_table = []\n",
    "k = 5  # Number of chunks to use\n",
    "\n",
    "# We need this helper so we can force Qwen to use \"Naive\" data without searching\n",
    "def manual_qwen_generate(context, question):\n",
    "    prompt = f\"\"\"Summarize the user's question based ONLY on the provided reviews below.\n",
    "Reviews:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "    return generate_with_qwen3(prompt, \"You are a helpful and professional assistant specialized in summarizing reviews.\")\n",
    "\n",
    "# Comparison loop\n",
    "for domain_name, query_text in queries.items():\n",
    "    print(f\"\\nProcessing Domain: {domain_name} | Query: {query_text}\")\n",
    "    \n",
    "    # ==========================================================\n",
    "    # SCENARIO A: BEFORE RETRIEVER (NAIVE / RANDOM DATA)\n",
    "    # We simulate \"No Search\" by just grabbing the first 5 docs from the dataset.\n",
    "    # ==========================================================\n",
    "    print(\"  > Running 'Before' (Naive) scenario...\")\n",
    "    \n",
    "    naive_docs = corpus[:k]\n",
    "    context_naive = \"\\n\\n\".join(naive_docs)\n",
    "    \n",
    "    # 1. Naive TextRank\n",
    "    try:\n",
    "        doc = nlp(context_naive[:100000])\n",
    "        tr_naive = \" \".join([s.text for s in doc._.textrank.summary(limit_sentences=2)])\n",
    "    except: tr_naive = \"Error\"\n",
    "    \n",
    "    # 2. Naive BART\n",
    "    try:\n",
    "        bart_naive = bart_pipeline(context_naive, max_length=150, min_length=30, truncation=True)[0]['summary_text']\n",
    "    except: bart_naive = \"Error\"\n",
    "    \n",
    "    # 3. Naive Qwen (Direct Generation, No Search)\n",
    "    qwen_naive = manual_qwen_generate(context_naive, query_text)\n",
    "\n",
    "    print(\"  > Judge is evaluating TextRank...\")\n",
    "    score_tr = get_judge_score(query_text, context_naive, tr_naive)\n",
    "    \n",
    "    print(\"  > Judge is evaluating BART...\")\n",
    "    score_bart = get_judge_score(query_text, context_naive, bart_naive)\n",
    "    \n",
    "    print(\"  > Judge is evaluating Qwen RAG...\")\n",
    "    score_qwen = get_judge_score(query_text, context_naive, qwen_naive)\n",
    "    \n",
    "    # Save \"Before\" Results\n",
    "    results_table.append({\"Domain\": domain_name, \"Mode\": \"Before (Naive)\", \"Model\": \"TextRank\", \"Output\": tr_naive, \"Judge Score\": score_tr})\n",
    "    results_table.append({\"Domain\": domain_name, \"Mode\": \"Before (Naive)\", \"Model\": \"BART\", \"Output\": bart_naive, \"Judge Score\": score_bart})\n",
    "    results_table.append({\"Domain\": domain_name, \"Mode\": \"Before (Naive)\", \"Model\": \"Qwen3\", \"Output\": qwen_naive, \"Judge Score\": score_qwen})\n",
    "\n",
    "\n",
    "\n",
    "    # ==========================================================\n",
    "    # SCENARIO B: AFTER RETRIEVER (RAG / RELEVANT DATA)\n",
    "    # We use the Retriever to find the top 5 BEST reviews.\n",
    "    # ==========================================================\n",
    "    print(\"  > Running 'After' (Retriever) scenario...\")\n",
    "    \n",
    "    q_emb = embed_model_cpu.encode([query_text])\n",
    "    D, I = index.search(np.array(q_emb), k)\n",
    "    rag_docs = [corpus[i] for i in I[0]]\n",
    "    context_rag = \"\\n\\n\".join(rag_docs)\n",
    "    \n",
    "    # 1. TextRank\n",
    "    try:\n",
    "        doc = nlp(context_rag[:100000])\n",
    "        tr_retriever = \" \".join([s.text for s in doc._.textrank.summary(limit_sentences=2)])\n",
    "    except: tr_retriever = \"Error\"\n",
    "    \n",
    "    # 2. BART\n",
    "    try:\n",
    "        bart_retriever = bart_pipeline(context_rag, max_length=150, min_length=30, truncation=True)[0]['summary_text']\n",
    "    except: bart_retriever = \"Error\"\n",
    "    \n",
    "    # 3. RAG Qwen (This is your standard RAG function)\n",
    "    qwen_rag = query_rag(query_text, index, corpus, k)\n",
    "\n",
    "    print(\"  > Judge is evaluating TextRank...\")\n",
    "    score_tr = get_judge_score(query_text, context_rag, tr_retriever)\n",
    "    \n",
    "    print(\"  > Judge is evaluating BART...\")\n",
    "    score_bart = get_judge_score(query_text, context_rag, bart_retriever)\n",
    "    \n",
    "    print(\"  > Judge is evaluating Qwen RAG...\")\n",
    "    score_qwen = get_judge_score(query_text, context_rag, qwen_rag)\n",
    "    \n",
    "    # Save \"After\" Results\n",
    "    results_table.append({\"Domain\": domain_name, \"Mode\": \"After (With Retriever)\", \"Model\": \"TextRank\", \"Output\": tr_retriever, \"Judge Score\": score_tr})\n",
    "    results_table.append({\"Domain\": domain_name, \"Mode\": \"After (With Retriever)\", \"Model\": \"BART\", \"Output\": bart_retriever, \"Judge Score\": score_bart})\n",
    "    results_table.append({\"Domain\": domain_name, \"Mode\": \"After (RAG)\", \"Model\": \"Qwen3\", \"Output\": qwen_rag, \"Judge Score\": score_qwen})\n",
    "\n",
    "df = pd.DataFrame(results_table)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = df.sort_values(by=[\"Domain\", \"Model\", \"Mode\"]) \n",
    "\n",
    "print(\"\\n--- FINAL COMPARISON: BEFORE vs AFTER RETRIEVER ---\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e669f0",
   "metadata": {},
   "source": [
    "Benchmark the generator models, such as extractive, abstractive, and generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f3347c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 160, but your input_length is only 139. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=69)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUNNING GENERATOR BENCHMARK ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 160, but your input_length is only 156. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=78)\n",
      "Your max_length is set to 160, but your input_length is only 141. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=70)\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Your max_length is set to 160, but your input_length is only 126. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=63)\n",
      "Your max_length is set to 160, but your input_length is only 143. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=71)\n",
      "Your max_length is set to 160, but your input_length is only 130. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=65)\n",
      "Your max_length is set to 160, but your input_length is only 152. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=76)\n",
      "Your max_length is set to 160, but your input_length is only 117. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=58)\n",
      "Your max_length is set to 160, but your input_length is only 102. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=51)\n",
      "Your max_length is set to 160, but your input_length is only 36. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n",
      "Your max_length is set to 160, but your input_length is only 147. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=73)\n",
      "Your max_length is set to 160, but your input_length is only 83. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n",
      "Your max_length is set to 160, but your input_length is only 61. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=30)\n",
      "Your max_length is set to 160, but your input_length is only 75. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=37)\n",
      "Your max_length is set to 160, but your input_length is only 49. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n",
      "Your max_length is set to 160, but your input_length is only 155. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=77)\n",
      "Your max_length is set to 160, but your input_length is only 126. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=63)\n",
      "Your max_length is set to 160, but your input_length is only 36. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n",
      "Your max_length is set to 160, but your input_length is only 143. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=71)\n",
      "Your max_length is set to 160, but your input_length is only 62. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=31)\n",
      "Your max_length is set to 160, but your input_length is only 36. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n",
      "Your max_length is set to 160, but your input_length is only 132. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n",
      "Your max_length is set to 160, but your input_length is only 69. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=34)\n",
      "Your max_length is set to 160, but your input_length is only 134. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=67)\n",
      "Your max_length is set to 160, but your input_length is only 108. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n",
      "Your max_length is set to 160, but your input_length is only 67. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 160, but your input_length is only 84. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=42)\n",
      "Your max_length is set to 160, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n",
      "Your max_length is set to 160, but your input_length is only 134. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=67)\n",
      "Your max_length is set to 160, but your input_length is only 82. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n",
      "Your max_length is set to 160, but your input_length is only 50. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n",
      "Your max_length is set to 160, but your input_length is only 131. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=65)\n",
      "Your max_length is set to 160, but your input_length is only 77. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=38)\n",
      "Your max_length is set to 160, but your input_length is only 80. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "Your max_length is set to 160, but your input_length is only 77. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=38)\n",
      "Your max_length is set to 160, but your input_length is only 87. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\n",
      "Your max_length is set to 160, but your input_length is only 59. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=29)\n",
      "Your max_length is set to 160, but your input_length is only 67. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 160, but your input_length is only 141. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=70)\n",
      "Your max_length is set to 160, but your input_length is only 105. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=52)\n",
      "Your max_length is set to 160, but your input_length is only 50. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n",
      "Your max_length is set to 160, but your input_length is only 45. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\n",
      "Your max_length is set to 160, but your input_length is only 84. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=42)\n",
      "Your max_length is set to 160, but your input_length is only 71. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\n",
      "Your max_length is set to 160, but your input_length is only 37. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n",
      "Your max_length is set to 160, but your input_length is only 137. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=68)\n",
      "Your max_length is set to 160, but your input_length is only 102. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=51)\n",
      "Your max_length is set to 160, but your input_length is only 86. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\n",
      "Your max_length is set to 160, but your input_length is only 66. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 160, but your input_length is only 83. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n",
      "Your max_length is set to 160, but your input_length is only 101. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 160, but your input_length is only 49. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n",
      "Your max_length is set to 160, but your input_length is only 76. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=38)\n",
      "Your max_length is set to 160, but your input_length is only 69. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=34)\n",
      "Your max_length is set to 160, but your input_length is only 109. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n",
      "Your max_length is set to 160, but your input_length is only 86. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\n",
      "Your max_length is set to 160, but your input_length is only 143. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=71)\n",
      "Your max_length is set to 160, but your input_length is only 111. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=55)\n",
      "Your max_length is set to 160, but your input_length is only 80. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "Your max_length is set to 160, but your input_length is only 61. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=30)\n",
      "Your max_length is set to 160, but your input_length is only 45. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\n",
      "Your max_length is set to 160, but your input_length is only 118. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=59)\n",
      "Your max_length is set to 160, but your input_length is only 67. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 160, but your input_length is only 148. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=74)\n",
      "Your max_length is set to 160, but your input_length is only 45. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\n",
      "Your max_length is set to 160, but your input_length is only 80. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "Your max_length is set to 160, but your input_length is only 79. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=39)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating ROUGE Scores...\n",
      "\n",
      "--- BENCHMARK RESULTS ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TextRank</td>\n",
       "      <td>0.2771</td>\n",
       "      <td>0.2121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BART</td>\n",
       "      <td>0.3197</td>\n",
       "      <td>0.2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen3</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>0.3020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  ROUGE-1  ROUGE-L\n",
       "0  TextRank   0.2771   0.2121\n",
       "1      BART   0.3197   0.2486\n",
       "2     Qwen3   0.3922   0.3020"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "ds_samsum_sample = ds_samsum.select(range(100))\n",
    "print(\"--- RUNNING GENERATOR BENCHMARK ---\")\n",
    "\n",
    "eval_results = []\n",
    "\n",
    "for i, item in enumerate(ds_samsum_sample):\n",
    "    dialogue = item['dialogue']\n",
    "    reference = item['summary']\n",
    "    \n",
    "    # TextRank\n",
    "    try:\n",
    "        doc = nlp(dialogue)\n",
    "        tr_sum = \" \".join([s.text for s in doc._.textrank.summary(limit_sentences=2)])\n",
    "    except: tr_sum = \"\"\n",
    "    \n",
    "    # BART\n",
    "    try:\n",
    "        bart_out = bart_pipeline(dialogue, max_length=160, min_length=5, truncation=True)\n",
    "        bart_sum = bart_out[0]['summary_text']\n",
    "    except: bart_sum = \"\"\n",
    "    \n",
    "    # Qwen3\n",
    "    prompt = f\"\"\"Summarize the conversation below in one sentence.\n",
    "Conversation:\n",
    "{dialogue}\n",
    "\n",
    "Summary:\"\"\"\n",
    "    \n",
    "    qwen3_sum = generate_with_qwen3(prompt, content=\"You are a helpful assistant specialized in summarizing dialogues.\")\n",
    "    \n",
    "    eval_results.append({\n",
    "        \"Reference\": reference,\n",
    "        \"TextRank\": tr_sum,\n",
    "        \"BART\": bart_sum,\n",
    "        \"Qwen3\": qwen3_sum\n",
    "    })\n",
    "    \n",
    "# COMPUTE SCORES\n",
    "print(\"\\nCalculating ROUGE Scores...\")\n",
    "refs = [r['Reference'] for r in eval_results]\n",
    "preds_tr = [r['TextRank'] for r in eval_results]\n",
    "preds_bart = [r['BART'] for r in eval_results]\n",
    "preds_qwen3 = [r['Qwen3'] for r in eval_results]\n",
    "\n",
    "score_tr = rouge.compute(predictions=preds_tr, references=refs)\n",
    "score_bart = rouge.compute(predictions=preds_bart, references=refs)\n",
    "score_qwen3 = rouge.compute(predictions=preds_qwen3, references=refs)\n",
    "\n",
    "df_scores = pd.DataFrame([\n",
    "    {\"Model\": \"TextRank\", \"ROUGE-1\": score_tr['rouge1'], \"ROUGE-L\": score_tr['rougeL']},\n",
    "    {\"Model\": \"BART\",     \"ROUGE-1\": score_bart['rouge1'], \"ROUGE-L\": score_bart['rougeL']},\n",
    "    {\"Model\": \"Qwen3\",  \"ROUGE-1\": score_qwen3['rouge1'], \"ROUGE-L\": score_qwen3['rougeL']}\n",
    "])\n",
    "\n",
    "print(\"\\n--- BENCHMARK RESULTS ---\")\n",
    "display(df_scores.round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
