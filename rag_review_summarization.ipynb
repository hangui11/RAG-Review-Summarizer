{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c761638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "c:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\n",
      "Running on: cuda\n",
      "Libraries loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pytextrank\n",
    "import evaluate\n",
    "# Setup Device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Running on: {DEVICE}\")\n",
    "\n",
    "# Model Config\n",
    "RETRIEVER_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "GENERATOR_MODEL_ID = \"Qwen/Qwen3-4B-Instruct-2507\" \n",
    "\n",
    "print(\"Libraries loaded successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e43af459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LOADING DATASETS ---\n",
      "Downloading Beauty Dataset (may take a moment)...\n",
      "Downloading Music Dataset...\n",
      "Beauty Dataset Loaded: 701528 rows\n",
      "Music Dataset Loaded: 130434 rows\n",
      "SAMSum Dataset Loaded: 819 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"--- LOADING DATASETS ---\")\n",
    "\n",
    "# 1. Define Direct URLs to the raw data files\n",
    "# We bypass the blocked loading script by pointing directly to the .jsonl files in the repo\n",
    "url_beauty = \"https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/resolve/main/raw/review_categories/All_Beauty.jsonl\"\n",
    "url_music = \"https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/resolve/main/raw/review_categories/Digital_Music.jsonl\"\n",
    "\n",
    "print(\"Downloading Beauty Dataset (may take a moment)...\")\n",
    "# We use \"json\" builder because the files are in JSON Lines format\n",
    "ds_beauty = load_dataset(\"json\", data_files={\"train\": url_beauty}, split=\"train\")\n",
    "\n",
    "print(\"Downloading Music Dataset...\")\n",
    "ds_music = load_dataset(\"json\", data_files={\"train\": url_music}, split=\"train\")\n",
    "\n",
    "# 2. Load SAMSum (Benchmark Data)\n",
    "# Only loading 'test' split to keep it lightweight\n",
    "ds_samsum = load_dataset(\"knkarthick/samsum\", split=\"test\")\n",
    "\n",
    "print(f\"Beauty Dataset Loaded: {len(ds_beauty)} rows\")\n",
    "print(f\"Music Dataset Loaded: {len(ds_music)} rows\")\n",
    "print(f\"SAMSum Dataset Loaded: {len(ds_samsum)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e6dbfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Beauty Corpus...\n",
      "Preparing Music Corpus...\n"
     ]
    }
   ],
   "source": [
    "def prepare_full_corpus(dataset, limit=100000):\n",
    "    \"\"\"\n",
    "    Converts dataset rows to a list of strings.\n",
    "    Limits to 100k rows to keep RAM usage safe during prototyping.\n",
    "    Set limit=None to use everything.\n",
    "    \"\"\"\n",
    "    corpus = []\n",
    "    # We combine Title + Text for better context\n",
    "    for i, row in enumerate(dataset):\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "        text = f\"Rating: {row['rating']}\\nTitle: {row['title']}\\nReview: {row['text']}\"\n",
    "        corpus.append(text)\n",
    "    return corpus\n",
    "\n",
    "print(\"Preparing Beauty Corpus...\")\n",
    "corpus_beauty = prepare_full_corpus(ds_beauty)\n",
    "\n",
    "print(\"Preparing Music Corpus...\")\n",
    "corpus_music = prepare_full_corpus(ds_music)\n",
    "\n",
    "corpus = corpus_beauty+corpus_music\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51c926ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PHASE 1: BUILDING INDICES ---\n",
      "Loading Embedder sentence-transformers/all-MiniLM-L6-v2 on GPU...\n",
      "Encoding 200000 documents...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2291b2c7584430faf03b7813cfde1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding complete. Cleaning up VRAM...\n",
      "SUCCESS: Indices built and GPU memory cleared.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- PHASE 1: BUILDING INDICES ---\")\n",
    "\n",
    "def build_faiss_index_and_clean(corpus, model_name):\n",
    "    print(f\"Loading Embedder {model_name} on GPU...\")\n",
    "    embed_model = SentenceTransformer(model_name, device=DEVICE)\n",
    "    \n",
    "    print(f\"Encoding {len(corpus)} documents...\")\n",
    "    # Batch size 32 is safe for 8GB VRAM\n",
    "    embeddings = embed_model.encode(corpus, batch_size=32, show_progress_bar=True, convert_to_numpy=True)\n",
    "    \n",
    "    # Build FAISS Index\n",
    "    vector_dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(vector_dim)\n",
    "    index.add(embeddings)\n",
    "    \n",
    "    print(\"Encoding complete. Cleaning up VRAM...\")\n",
    "    \n",
    "    # --- CRITICAL MEMORY CLEANUP ---\n",
    "    del embed_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # -------------------------------\n",
    "    \n",
    "    return index\n",
    "\n",
    "# Build Indices sequentially\n",
    "index = build_faiss_index_and_clean(corpus, RETRIEVER_MODEL)\n",
    "\n",
    "print(\"SUCCESS: Indices built and GPU memory cleared.\")\n",
    "\n",
    "# Re-load embedder just for encoding QUERIES later (CPU is fine for single queries to save VRAM)\n",
    "# or keep it on CPU to avoid VRAM conflict.\n",
    "embed_model_cpu = SentenceTransformer(RETRIEVER_MODEL, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ffa25b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen/Qwen3-4B-Instruct-2507...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bb030125214aaca15272a4f9090980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Qwen/Qwen3-4B-Instruct-2507 loaded.\n"
     ]
    }
   ],
   "source": [
    "# 4-bit Quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(f\"Loading {GENERATOR_MODEL_ID}...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(GENERATOR_MODEL_ID, trust_remote_code=True)\n",
    "    \n",
    "    model_qwen3 = AutoModelForCausalLM.from_pretrained(\n",
    "        GENERATOR_MODEL_ID, \n",
    "        quantization_config=bnb_config, \n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # Safety check for pad token\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "    print(f\"Success! {GENERATOR_MODEL_ID} loaded.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Qwen3: {e}\")\n",
    "\n",
    "def generate_with_qwen3(prompt, content, temperature=0.7):\n",
    "    # 1. Prepare Messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    # 2. Tokenize & Format\n",
    "    # Qwen3 uses standard chat templates. We want the full prompt ready for the model.\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "    # 3. Generate (With Memory Optimization)\n",
    "    # torch.inference_mode() is faster and uses less memory than standard generation\n",
    "    with torch.inference_mode():\n",
    "        generated_ids = model_qwen3.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=512,       # Increased slightly for better summaries\n",
    "            temperature=temperature,\n",
    "            top_p=0.8,                # Recommended for Qwen\n",
    "            top_k=20,                 # Recommended for Qwen\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    # 4. Smart Extraction (The Fix)\n",
    "    # Instead of splitting strings, we slice the tokens directly.\n",
    "    # We remove the input tokens from the output to leave ONLY the new response.\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    # 5. Decode\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d7bb436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag(query, index, corpus, k=5):\n",
    "    # 1. Encode query (CPU)\n",
    "    q_emb = embed_model_cpu.encode([query])\n",
    "    \n",
    "    # 2. Retrieve (FAISS)\n",
    "    D, I = index.search(np.array(q_emb), k)\n",
    "    retrieved_docs = [corpus[i] for i in I[0]]\n",
    "    \n",
    "    # 3. Format Context\n",
    "    context_str = \"\\n\\n\".join([f\"Review {i+1}: {doc}\" for i, doc in enumerate(retrieved_docs)])\n",
    "    \n",
    "    # 4. Construct Prompt (CLEAN TEXT ONLY)\n",
    "    prompt = f\"\"\"Summarize the user's question based ONLY on the provided reviews below. \n",
    "If the reviews discuss different products, specify which product has which pros/cons.\n",
    "\n",
    "Reviews:\n",
    "{context_str}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\"\"\"\n",
    "    return generate_with_qwen3(prompt, content=\"You are a helpful and professional assistant specialized in summarizing reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ad03c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_judge_score(question, source_text, summary_to_evaluate):\n",
    "    prompt = f\"\"\"\n",
    "You are a very strict, professional evaluator.\n",
    "Act as an expert teacher grading a student answer.\n",
    "\n",
    "User Question:\n",
    "{question}\n",
    "\n",
    "Source Text:\n",
    "{source_text}\n",
    "\n",
    "Summary to Evaluate:\n",
    "{summary_to_evaluate}\n",
    "\n",
    "Evaluate the summary from 1 to 10 based on ALL of the following criteria:\n",
    "\n",
    "1. Accuracy: The summary is factually correct and matches the source text.\n",
    "2. Faithfulness: The summary does NOT add information that is not explicitly supported by the source.\n",
    "3. Relevance: The summary directly answers the user question.\n",
    "4. Coverage: The summary includes the most important points needed to answer the question.\n",
    "5. Conciseness: The summary is clear, brief, and avoids unnecessary details.\n",
    "6. Coherence: The summary is logically structured and easy to understand.\n",
    "7. Redundancy: The summary avoids repetition.\n",
    "\n",
    "Final instruction:\n",
    "- Give a SINGLE score from 1 (very poor) to 10 (excellent).\n",
    "- Be strict.\n",
    "- Reply ONLY with the number (e.g., 7 or 10). Do not write sentences.\n",
    "\"\"\"\n",
    "    try:\n",
    "        # Generate the score\n",
    "        score_text = generate_with_qwen3(\n",
    "            prompt, \n",
    "            content=\"You are an impartial judge. Reply ONLY with a digit.\"\n",
    "        )\n",
    "        \n",
    "        # 1. Filter out all non-digits (keeps \"10\", \"5\", etc.)\n",
    "        digits = ''.join(filter(str.isdigit, score_text))\n",
    "        \n",
    "        # 2. Safety Check: If empty (model didn't reply with number), return default\n",
    "        if not digits:\n",
    "            return 3\n",
    "            \n",
    "        # 3. Convert to integer (Removing the [0] fixes the \"10\" bug)\n",
    "        score = int(digits)\n",
    "        \n",
    "        # 4. Cap the score at 10 just in case it outputs \"100\" or garbage\n",
    "        return min(score, 10)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Judge Error: {e}\")\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f6574ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUNNING BEFORE vs. AFTER RETRIEVER COMPARISON ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Domain: Beauty | Query: What do users with sensitive skin say about the texture and greasiness of the moisturizers?\n",
      "  > Running 'Before' (Naive) scenario...\n",
      "  > Judge is evaluating TextRank...\n",
      "  > Judge is evaluating BART...\n",
      "  > Judge is evaluating Qwen RAG...\n",
      "  > Running 'After' (Retriever) scenario...\n",
      "  > Judge is evaluating TextRank...\n",
      "  > Judge is evaluating BART...\n",
      "  > Judge is evaluating Qwen RAG...\n",
      "\n",
      "Processing Domain: Music | Query: Do customers think the sound quality justifies the price, and are there complaints about comfort?\n",
      "  > Running 'Before' (Naive) scenario...\n",
      "  > Judge is evaluating TextRank...\n",
      "  > Judge is evaluating BART...\n",
      "  > Judge is evaluating Qwen RAG...\n",
      "  > Running 'After' (Retriever) scenario...\n",
      "  > Judge is evaluating TextRank...\n",
      "  > Judge is evaluating BART...\n",
      "  > Judge is evaluating Qwen RAG...\n",
      "\n",
      "--- FINAL COMPARISON: BEFORE vs AFTER RETRIEVER ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Model</th>\n",
       "      <th>Output</th>\n",
       "      <th>Judge Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beauty</td>\n",
       "      <td>After (With Retriever)</td>\n",
       "      <td>BART</td>\n",
       "      <td>Review: Excellent for sensitive skin! Extremely moisturizing! Stock up because you're going to love how your skin feels and smells. Rating: 5.0 emphatically. Reviewer: \"I have pretty sensitive skin, and they feel great so far\"</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beauty</td>\n",
       "      <td>Before (Random Data)</td>\n",
       "      <td>BART</td>\n",
       "      <td>Review: This spray is really nice. It smells really good, goes on really fine, and does the trick. I will say it feels like you need a lot of it though to get the texture I want.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Beauty</td>\n",
       "      <td>After (With Retriever)</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>Users with sensitive skin praise the moisturizer for its smooth texture, quick absorption, and non-greasy feel. They note it is extremely moisturizing and does not cause breakouts or irritation, making it ideal for sensitive skin. There is no mention of greasiness, as all reviews emphasize that the product is pleasant, non-irritating, and absorbs well without leaving a greasy residue. \\n\\nProduct: All reviews refer to the same moisturizer, with no distinction between different products.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beauty</td>\n",
       "      <td>Before (Random Data)</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>The provided reviews do not contain information about users with sensitive skin or their experiences with texture and greasiness of moisturizers. Therefore, based solely on the reviews, the question cannot be addressed.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beauty</td>\n",
       "      <td>After (With Retriever)</td>\n",
       "      <td>TextRank</td>\n",
       "      <td>Rating: 5.0\\nTitle: Great for sensitive skin\\nReview: Excellent for sensitive skin! so if you have sensitive skin it's just wonderful it doesn't make me break out is just so good\\n\\nRating:</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beauty</td>\n",
       "      <td>Before (Random Data)</td>\n",
       "      <td>TextRank</td>\n",
       "      <td>Rating: 1.0\\nTitle: Synthetic feeling\\nReview: Felt synthetic\\n\\nRating: 5.0\\nTitle: A+\\nReview: Love it I am comparing to other brands with yucky chemicals so I'm gonna stick with this.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Music</td>\n",
       "      <td>After (With Retriever)</td>\n",
       "      <td>BART</td>\n",
       "      <td>The Fit is snug, quality is silky and a good thickness. Very comfortable. Also recvd two. Great product at a good price.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Music</td>\n",
       "      <td>Before (Random Data)</td>\n",
       "      <td>BART</td>\n",
       "      <td>Review: This spray is really nice. It smells really good, goes on really fine, and does the trick. I will say it feels like you need a lot of it though to get the texture I want.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Music</td>\n",
       "      <td>After (With Retriever)</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>The user is asking whether customers find the sound quality justifies the price and if there are complaints about comfort.\\n\\nSummary of relevant points from reviews:\\n\\n- Review 1: Mentions \"excellent sound\" and only minor wear; no mention of price or comfort complaints.\\n- Review 2: Notes the product is \"a little bit pricey\" but acknowledges comfort and healing benefits; no direct complaint about comfort.\\n- Review 3: Describes the product as high quality and comfortable, calls it \"tad pricey\" but considers it worth it — no comfort complaints.\\n- Review 4: Highlights comfort (\"comfortable enough to wear all day\") and cost savings; no mention of sound quality or complaints.\\n- Review 5: Emphasizes comfort (\"very comfortable\") and quality, with no mention of price or sound.\\n\\nNo reviews explicitly mention sound quality as a factor in price justification, and no complaints about discomfort are present. While one review notes the product is \"a little bit pricey,\" this is not a complaint about comfort.\\n\\nFinal summary:\\n\\nCustomers do not express complaints about comfort — all reviews highlight comfort or comfort-related benefits. Sound quality is mentioned only in Review 1 (\"excellent sound\"), but there is no explicit evaluation of whether it justifies the price. Therefore, based on the reviews:\\n\\n- There is no evidence that sound quality is discussed as a justification for price.\\n- There are no complaints about comfort.\\n\\nAnswer: No, customers do not generally complain about comfort, and sound quality is not explicitly linked to price justification in the reviews.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Music</td>\n",
       "      <td>Before (Random Data)</td>\n",
       "      <td>Qwen3</td>\n",
       "      <td>The user's question is based on a misunderstanding of the review content. The reviews discuss a scent spray product, not sound quality, and there are no mentions of price or comfort in the context of sound. Therefore, customers do not think sound quality is relevant, and there are no complaints about comfort as the product is not related to sound or physical comfort in the way described. The actual reviews pertain to scent, texture, and fragrance preference, not sound quality or comfort in a physical sense.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Music</td>\n",
       "      <td>After (With Retriever)</td>\n",
       "      <td>TextRank</td>\n",
       "      <td>Rating: 5.0\\nTitle: Excellent sound, and only minor indications that it had ...\\n Review: Excellent sound, and only minor indications that it had ever been out of the package.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Music</td>\n",
       "      <td>Before (Random Data)</td>\n",
       "      <td>TextRank</td>\n",
       "      <td>Rating: 1.0\\nTitle: Synthetic feeling\\nReview: Felt synthetic\\n\\nRating: 5.0\\nTitle: A+\\nReview: Love it I am comparing to other brands with yucky chemicals so I'm gonna stick with this.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Domain                    Mode     Model  \\\n",
       "4   Beauty  After (With Retriever)      BART   \n",
       "1   Beauty    Before (Random Data)      BART   \n",
       "5   Beauty  After (With Retriever)     Qwen3   \n",
       "2   Beauty    Before (Random Data)     Qwen3   \n",
       "3   Beauty  After (With Retriever)  TextRank   \n",
       "0   Beauty    Before (Random Data)  TextRank   \n",
       "10   Music  After (With Retriever)      BART   \n",
       "7    Music    Before (Random Data)      BART   \n",
       "11   Music  After (With Retriever)     Qwen3   \n",
       "8    Music    Before (Random Data)     Qwen3   \n",
       "9    Music  After (With Retriever)  TextRank   \n",
       "6    Music    Before (Random Data)  TextRank   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Output  \\\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Review: Excellent for sensitive skin! Extremely moisturizing! Stock up because you're going to love how your skin feels and smells. Rating: 5.0 emphatically. Reviewer: \"I have pretty sensitive skin, and they feel great so far\"   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Review: This spray is really nice. It smells really good, goes on really fine, and does the trick. I will say it feels like you need a lot of it though to get the texture I want.   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Users with sensitive skin praise the moisturizer for its smooth texture, quick absorption, and non-greasy feel. They note it is extremely moisturizing and does not cause breakouts or irritation, making it ideal for sensitive skin. There is no mention of greasiness, as all reviews emphasize that the product is pleasant, non-irritating, and absorbs well without leaving a greasy residue. \\n\\nProduct: All reviews refer to the same moisturizer, with no distinction between different products.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The provided reviews do not contain information about users with sensitive skin or their experiences with texture and greasiness of moisturizers. Therefore, based solely on the reviews, the question cannot be addressed.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Rating: 5.0\\nTitle: Great for sensitive skin\\nReview: Excellent for sensitive skin! so if you have sensitive skin it's just wonderful it doesn't make me break out is just so good\\n\\nRating:   \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Rating: 1.0\\nTitle: Synthetic feeling\\nReview: Felt synthetic\\n\\nRating: 5.0\\nTitle: A+\\nReview: Love it I am comparing to other brands with yucky chemicals so I'm gonna stick with this.   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    The Fit is snug, quality is silky and a good thickness. Very comfortable. Also recvd two. Great product at a good price.   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Review: This spray is really nice. It smells really good, goes on really fine, and does the trick. I will say it feels like you need a lot of it though to get the texture I want.   \n",
       "11  The user is asking whether customers find the sound quality justifies the price and if there are complaints about comfort.\\n\\nSummary of relevant points from reviews:\\n\\n- Review 1: Mentions \"excellent sound\" and only minor wear; no mention of price or comfort complaints.\\n- Review 2: Notes the product is \"a little bit pricey\" but acknowledges comfort and healing benefits; no direct complaint about comfort.\\n- Review 3: Describes the product as high quality and comfortable, calls it \"tad pricey\" but considers it worth it — no comfort complaints.\\n- Review 4: Highlights comfort (\"comfortable enough to wear all day\") and cost savings; no mention of sound quality or complaints.\\n- Review 5: Emphasizes comfort (\"very comfortable\") and quality, with no mention of price or sound.\\n\\nNo reviews explicitly mention sound quality as a factor in price justification, and no complaints about discomfort are present. While one review notes the product is \"a little bit pricey,\" this is not a complaint about comfort.\\n\\nFinal summary:\\n\\nCustomers do not express complaints about comfort — all reviews highlight comfort or comfort-related benefits. Sound quality is mentioned only in Review 1 (\"excellent sound\"), but there is no explicit evaluation of whether it justifies the price. Therefore, based on the reviews:\\n\\n- There is no evidence that sound quality is discussed as a justification for price.\\n- There are no complaints about comfort.\\n\\nAnswer: No, customers do not generally complain about comfort, and sound quality is not explicitly linked to price justification in the reviews.   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             The user's question is based on a misunderstanding of the review content. The reviews discuss a scent spray product, not sound quality, and there are no mentions of price or comfort in the context of sound. Therefore, customers do not think sound quality is relevant, and there are no complaints about comfort as the product is not related to sound or physical comfort in the way described. The actual reviews pertain to scent, texture, and fragrance preference, not sound quality or comfort in a physical sense.   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Rating: 5.0\\nTitle: Excellent sound, and only minor indications that it had ...\\n Review: Excellent sound, and only minor indications that it had ever been out of the package.     \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Rating: 1.0\\nTitle: Synthetic feeling\\nReview: Felt synthetic\\n\\nRating: 5.0\\nTitle: A+\\nReview: Love it I am comparing to other brands with yucky chemicals so I'm gonna stick with this.   \n",
       "\n",
       "    Judge Score  \n",
       "4             5  \n",
       "1             3  \n",
       "5            10  \n",
       "2             1  \n",
       "3             8  \n",
       "0             2  \n",
       "10            8  \n",
       "7             2  \n",
       "11            9  \n",
       "8             1  \n",
       "9             2  \n",
       "6             2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"--- RUNNING BEFORE vs. AFTER RETRIEVER COMPARISON ---\")\n",
    "\n",
    "# --- 1. SETUP BASELINES ---\n",
    "# Setup Spacy TextRank\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    nlp = spacy.blank(\"en\")\n",
    "\n",
    "if \"textrank\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"textrank\")\n",
    "\n",
    "# Setup BART (Abstractive Summarization)\n",
    "# We set truncation=True because BART cannot handle infinite text\n",
    "bart_pipeline = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0) # Change to -1 for CPU\n",
    "\n",
    "# --- 2. DEFINE QUERIES ---\n",
    "queries = {\n",
    "    \"Beauty\": \"What do users with sensitive skin say about the texture and greasiness of the moisturizers?\",\n",
    "    \"Music\": \"Do customers think the sound quality justifies the price, and are there complaints about comfort?\"\n",
    "}\n",
    "\n",
    "results_table = []\n",
    "k = 5  # Number of chunks to use\n",
    "\n",
    "# --- 3. HELPER FUNCTION FOR QWEN ---\n",
    "# We need this helper so we can force Qwen to use \"Naive\" data without searching\n",
    "def manual_qwen_generate(context, question):\n",
    "    prompt = f\"\"\"Summarize the user's question based ONLY on the provided reviews below.\n",
    "Reviews:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "    return generate_with_qwen3(prompt, \"You are a helpful and professional assistant specialized in summarizing reviews.\")\n",
    "\n",
    "\n",
    "# --- 4. COMPARISON LOOP ---\n",
    "\n",
    "for domain_name, query_text in queries.items():\n",
    "    print(f\"\\nProcessing Domain: {domain_name} | Query: {query_text}\")\n",
    "    \n",
    "    # ==========================================================\n",
    "    # SCENARIO A: BEFORE RETRIEVER (NAIVE / RANDOM DATA)\n",
    "    # We simulate \"No Search\" by just grabbing the first 5 docs from the dataset.\n",
    "    # ==========================================================\n",
    "    print(\"  > Running 'Before' (Naive) scenario...\")\n",
    "    \n",
    "    naive_docs = corpus[:k]  # Just the first 5 reviews in the list (likely irrelevant)\n",
    "    context_naive = \"\\n\\n\".join(naive_docs)\n",
    "    \n",
    "    # 1. Naive TextRank\n",
    "    try:\n",
    "        doc = nlp(context_naive[:100000])\n",
    "        tr_naive = \" \".join([s.text for s in doc._.textrank.summary(limit_sentences=2)])\n",
    "    except: tr_naive = \"Error\"\n",
    "    \n",
    "    # 2. Naive BART\n",
    "    try:\n",
    "        bart_naive = bart_pipeline(context_naive, max_length=150, min_length=30, truncation=True)[0]['summary_text']\n",
    "    except: bart_naive = \"Error\"\n",
    "    \n",
    "    # 3. Naive Qwen (Direct Generation, No Search)\n",
    "    qwen_naive = manual_qwen_generate(context_naive, query_text)\n",
    "\n",
    "    print(\"  > Judge is evaluating TextRank...\")\n",
    "    score_tr = get_judge_score(query_text, context_naive, tr_naive)\n",
    "    \n",
    "    print(\"  > Judge is evaluating BART...\")\n",
    "    score_bart = get_judge_score(query_text, context_naive, bart_naive)\n",
    "    \n",
    "    print(\"  > Judge is evaluating Qwen RAG...\")\n",
    "    score_qwen = get_judge_score(query_text, context_naive, qwen_naive)\n",
    "    \n",
    "\n",
    "\n",
    "    # Save \"Before\" Results\n",
    "    results_table.append({\"Domain\": domain_name, \"Mode\": \"Before (Random Data)\", \"Model\": \"TextRank\", \"Output\": tr_naive, \"Judge Score\": score_tr})\n",
    "    results_table.append({\"Domain\": domain_name, \"Mode\": \"Before (Random Data)\", \"Model\": \"BART\", \"Output\": bart_naive, \"Judge Score\": score_bart})\n",
    "    results_table.append({\"Domain\": domain_name, \"Mode\": \"Before (Random Data)\", \"Model\": \"Qwen3\", \"Output\": qwen_naive, \"Judge Score\": score_qwen})\n",
    "\n",
    "\n",
    "\n",
    "    # ==========================================================\n",
    "    # SCENARIO B: AFTER RETRIEVER (RAG / RELEVANT DATA)\n",
    "    # We use the Retriever to find the top 5 BEST reviews.\n",
    "    # ==========================================================\n",
    "    print(\"  > Running 'After' (Retriever) scenario...\")\n",
    "    \n",
    "    q_emb = embed_model_cpu.encode([query_text])\n",
    "    D, I = index.search(np.array(q_emb), k)\n",
    "    rag_docs = [corpus[i] for i in I[0]]\n",
    "    context_rag = \"\\n\\n\".join(rag_docs)\n",
    "    \n",
    "    # 1. TextRank\n",
    "    try:\n",
    "        doc = nlp(context_rag[:100000])\n",
    "        tr_retriever = \" \".join([s.text for s in doc._.textrank.summary(limit_sentences=2)])\n",
    "    except: tr_retriever = \"Error\"\n",
    "    \n",
    "    # 2. BART\n",
    "    try:\n",
    "        bart_retriever = bart_pipeline(context_rag, max_length=150, min_length=30, truncation=True)[0]['summary_text']\n",
    "    except: bart_retriever = \"Error\"\n",
    "    \n",
    "    # 3. RAG Qwen (This is your standard RAG function)\n",
    "    # We can reuse the manual helper with the GOOD context to be consistent\n",
    "    qwen_rag = query_rag(query_text, index, corpus, k)\n",
    "\n",
    "\n",
    "    print(\"  > Judge is evaluating TextRank...\")\n",
    "    score_tr = get_judge_score(query_text, context_rag, tr_retriever)\n",
    "    \n",
    "    print(\"  > Judge is evaluating BART...\")\n",
    "    score_bart = get_judge_score(query_text, context_rag, bart_retriever)\n",
    "    \n",
    "    print(\"  > Judge is evaluating Qwen RAG...\")\n",
    "    score_qwen = get_judge_score(query_text, context_rag, qwen_rag)\n",
    "    \n",
    "    # Save \"After\" Results\n",
    "    results_table.append({\"Domain\": domain_name, \"Mode\": \"After (With Retriever)\", \"Model\": \"TextRank\", \"Output\": tr_retriever, \"Judge Score\": score_tr})\n",
    "    results_table.append({\"Domain\": domain_name, \"Mode\": \"After (With Retriever)\", \"Model\": \"BART\", \"Output\": bart_retriever, \"Judge Score\": score_bart})\n",
    "    results_table.append({\"Domain\": domain_name, \"Mode\": \"After (With Retriever)\", \"Model\": \"Qwen3\", \"Output\": qwen_rag, \"Judge Score\": score_qwen})\n",
    "\n",
    "# --- 5. DISPLAY RESULTS ---\n",
    "df = pd.DataFrame(results_table)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# We sort to keep Before/After pairs together for easy reading\n",
    "df = df.sort_values(by=[\"Domain\", \"Model\", \"Mode\"]) \n",
    "\n",
    "print(\"\\n--- FINAL COMPARISON: BEFORE vs AFTER RETRIEVER ---\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f3347c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAMSum dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 307, but your input_length is only 139. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=69)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUNNING GENERATOR BENCHMARK ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 344, but your input_length is only 156. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=78)\n",
      "Your max_length is set to 477, but your input_length is only 180. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=90)\n",
      "Your max_length is set to 352, but your input_length is only 141. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=70)\n",
      "Your max_length is set to 978, but your input_length is only 341. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=170)\n",
      "Your max_length is set to 1442, but your input_length is only 414. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=207)\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Your max_length is set to 928, but your input_length is only 328. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=164)\n",
      "Your max_length is set to 332, but your input_length is only 126. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=63)\n",
      "Your max_length is set to 370, but your input_length is only 143. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=71)\n",
      "Your max_length is set to 314, but your input_length is only 130. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=65)\n",
      "Your max_length is set to 312, but your input_length is only 152. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=76)\n",
      "Your max_length is set to 291, but your input_length is only 117. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=58)\n",
      "Your max_length is set to 250, but your input_length is only 102. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=51)\n",
      "Your max_length is set to 508, but your input_length is only 161. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=80)\n",
      "Your max_length is set to 344, but your input_length is only 147. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=73)\n",
      "Your max_length is set to 157, but your input_length is only 83. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n",
      "Your max_length is set to 523, but your input_length is only 192. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=96)\n",
      "Your max_length is set to 1782, but your input_length is only 488. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=244)\n",
      "Your max_length is set to 106, but your input_length is only 61. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=30)\n",
      "Your max_length is set to 1765, but your input_length is only 546. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=273)\n",
      "Your max_length is set to 813, but your input_length is only 255. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=127)\n",
      "Your max_length is set to 1230, but your input_length is only 341. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=170)\n",
      "Your max_length is set to 126, but your input_length is only 75. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=37)\n",
      "Your max_length is set to 561, but your input_length is only 202. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=101)\n",
      "Your max_length is set to 1139, but your input_length is only 391. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=195)\n",
      "Your max_length is set to 534, but your input_length is only 155. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=77)\n",
      "Your max_length is set to 265, but your input_length is only 126. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=63)\n",
      "Your max_length is set to 1332, but your input_length is only 428. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=214)\n",
      "Your max_length is set to 345, but your input_length is only 143. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=71)\n",
      "Your max_length is set to 102, but your input_length is only 62. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=31)\n",
      "Your max_length is set to 356, but your input_length is only 132. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n",
      "Your max_length is set to 107, but your input_length is only 69. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=34)\n",
      "Your max_length is set to 345, but your input_length is only 134. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=67)\n",
      "Your max_length is set to 227, but your input_length is only 108. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n",
      "Your max_length is set to 138, but your input_length is only 67. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 532, but your input_length is only 192. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=96)\n",
      "Your max_length is set to 1144, but your input_length is only 349. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=174)\n",
      "Your max_length is set to 176, but your input_length is only 84. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=42)\n",
      "Your max_length is set to 1113, but your input_length is only 340. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=170)\n",
      "Your min_length=5 must be inferior than your max_length=-17.\n",
      "Your max_length is set to 192, but your input_length is only 134. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=67)\n",
      "Your max_length is set to 162, but your input_length is only 82. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n",
      "Your max_length is set to 626, but your input_length is only 228. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=114)\n",
      "Your max_length is set to 263, but your input_length is only 196. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=98)\n",
      "Your max_length is set to 84, but your input_length is only 50. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n",
      "Your max_length is set to 360, but your input_length is only 131. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=65)\n",
      "Your max_length is set to 483, but your input_length is only 162. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=81)\n",
      "Your max_length is set to 512, but your input_length is only 212. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=106)\n",
      "Your max_length is set to 169, but your input_length is only 77. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=38)\n",
      "Your max_length is set to 135, but your input_length is only 80. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "Your max_length is set to 141, but your input_length is only 77. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=38)\n",
      "Your max_length is set to 189, but your input_length is only 87. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\n",
      "Your max_length is set to 72, but your input_length is only 59. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=29)\n",
      "Your max_length is set to 132, but your input_length is only 67. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 350, but your input_length is only 141. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=70)\n",
      "Your max_length is set to 237, but your input_length is only 105. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=52)\n",
      "Your max_length is set to 445, but your input_length is only 162. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=81)\n",
      "Your max_length is set to 52, but your input_length is only 45. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\n",
      "Your max_length is set to 186, but your input_length is only 84. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=42)\n",
      "Your max_length is set to 884, but your input_length is only 293. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=146)\n",
      "Your max_length is set to 122, but your input_length is only 71. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\n",
      "Your min_length=5 must be inferior than your max_length=3.\n",
      "c:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1633: UserWarning: Unfeasible length constraints: `min_length` (5) is larger than the maximum possible length (3). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n",
      "Your max_length is set to 308, but your input_length is only 137. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=68)\n",
      "Your max_length is set to 542, but your input_length is only 201. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=100)\n",
      "Your max_length is set to 244, but your input_length is only 102. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=51)\n",
      "Your max_length is set to 171, but your input_length is only 86. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\n",
      "Your max_length is set to 105, but your input_length is only 66. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 170, but your input_length is only 83. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n",
      "Your max_length is set to 231, but your input_length is only 101. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 1518, but your input_length is only 414. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=207)\n",
      "Your max_length is set to 170, but your input_length is only 76. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=38)\n",
      "Your max_length is set to 963, but your input_length is only 301. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=150)\n",
      "Your max_length is set to 517, but your input_length is only 176. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=88)\n",
      "Your max_length is set to 491, but your input_length is only 208. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=104)\n",
      "Your max_length is set to 127, but your input_length is only 69. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=34)\n",
      "Your max_length is set to 1343, but your input_length is only 425. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=212)\n",
      "Your max_length is set to 268, but your input_length is only 109. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n",
      "Your max_length is set to 374, but your input_length is only 162. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=81)\n",
      "Your max_length is set to 184, but your input_length is only 86. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\n",
      "Your max_length is set to 363, but your input_length is only 143. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=71)\n",
      "Your max_length is set to 518, but your input_length is only 208. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=104)\n",
      "Your max_length is set to 245, but your input_length is only 111. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=55)\n",
      "Your max_length is set to 1015, but your input_length is only 338. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=169)\n",
      "Your max_length is set to 153, but your input_length is only 80. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "Your max_length is set to 62, but your input_length is only 61. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=30)\n",
      "Your max_length is set to 491, but your input_length is only 194. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=97)\n",
      "Your max_length is set to 764, but your input_length is only 224. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=112)\n",
      "Your max_length is set to 254, but your input_length is only 118. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=59)\n",
      "Your max_length is set to 82, but your input_length is only 67. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 444, but your input_length is only 148. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=74)\n",
      "Your max_length is set to 53, but your input_length is only 45. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\n",
      "Your max_length is set to 163, but your input_length is only 80. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "Your max_length is set to 148, but your input_length is only 79. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=39)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating ROUGE Scores...\n",
      "\n",
      "--- BENCHMARK RESULTS ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TextRank (Baseline)</td>\n",
       "      <td>0.2775</td>\n",
       "      <td>0.2128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BART (Baseline)</td>\n",
       "      <td>0.3120</td>\n",
       "      <td>0.2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen3</td>\n",
       "      <td>0.3917</td>\n",
       "      <td>0.3033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  ROUGE-1  ROUGE-L\n",
       "0  TextRank (Baseline)   0.2775   0.2128\n",
       "1      BART (Baseline)   0.3120   0.2431\n",
       "2                Qwen3   0.3917   0.3033"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. SETUP DATA\n",
    "print(\"Loading SAMSum dataset...\")\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "ds_samsum_sample = ds_samsum.select(range(100))\n",
    "print(\"--- RUNNING GENERATOR BENCHMARK ---\")\n",
    "\n",
    "eval_results = []\n",
    "\n",
    "for i, item in enumerate(ds_samsum_sample):\n",
    "    dialogue = item['dialogue']\n",
    "    reference = item['summary']\n",
    "    \n",
    "    # --- MODEL 1: TextRank ---\n",
    "    try:\n",
    "        doc = nlp(dialogue)\n",
    "        # Limit to 2 sentences because chats are short\n",
    "        tr_sum = \" \".join([s.text for s in doc._.textrank.summary(limit_sentences=2)])\n",
    "    except: tr_sum = \"\"\n",
    "    \n",
    "    # --- MODEL 2: BART ---\n",
    "    try:\n",
    "        # Chats are short, so we reduce max_length\n",
    "        bart_out = bart_pipeline(dialogue, max_length=len(dialogue)-100, min_length=5, truncation=True)\n",
    "        bart_sum = bart_out[0]['summary_text']\n",
    "    except: bart_sum = \"\"\n",
    "    \n",
    "    # --- MODEL 3: Qwen3 (Your LLM) ---\n",
    "    prompt = f\"\"\"Summarize the conversation below in one sentence.\n",
    "Conversation:\n",
    "{dialogue}\n",
    "\n",
    "Summary:\"\"\"\n",
    "    \n",
    "    # Using your existing generator function\n",
    "    qwen3_sum = generate_with_qwen3(prompt, content=\"You are a helpful assistant specialized in summarizing dialogues.\")\n",
    "    \n",
    "    eval_results.append({\n",
    "        \"Reference\": reference,\n",
    "        \"TextRank\": tr_sum,\n",
    "        \"BART\": bart_sum,\n",
    "        \"Qwen3\": qwen3_sum\n",
    "    })\n",
    "    \n",
    "    # print(f\"Processed {i+1}/{len(ds_samsum_sample)}\")\n",
    "\n",
    "# 3. COMPUTE SCORES\n",
    "print(\"\\nCalculating ROUGE Scores...\")\n",
    "refs = [r['Reference'] for r in eval_results]\n",
    "preds_tr = [r['TextRank'] for r in eval_results]\n",
    "preds_bart = [r['BART'] for r in eval_results]\n",
    "preds_qwen3 = [r['Qwen3'] for r in eval_results]\n",
    "\n",
    "score_tr = rouge.compute(predictions=preds_tr, references=refs)\n",
    "score_bart = rouge.compute(predictions=preds_bart, references=refs)\n",
    "score_qwen3 = rouge.compute(predictions=preds_qwen3, references=refs)\n",
    "\n",
    "# 4. DISPLAY\n",
    "df_scores = pd.DataFrame([\n",
    "    {\"Model\": \"TextRank (Baseline)\", \"ROUGE-1\": score_tr['rouge1'], \"ROUGE-L\": score_tr['rougeL']},\n",
    "    {\"Model\": \"BART (Baseline)\",     \"ROUGE-1\": score_bart['rouge1'], \"ROUGE-L\": score_bart['rougeL']},\n",
    "    {\"Model\": \"Qwen3\",  \"ROUGE-1\": score_qwen3['rouge1'], \"ROUGE-L\": score_qwen3['rougeL']}\n",
    "])\n",
    "\n",
    "print(\"\\n--- BENCHMARK RESULTS ---\")\n",
    "# Rounding for cleaner display\n",
    "display(df_scores.round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
